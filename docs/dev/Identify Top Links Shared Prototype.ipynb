{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data & Making Dataframes\n",
    "The code below was run on a subset of data from January 31st, 2020 for the hour of 21:00:00. The tweet ids have been retreived and hydrated from https://github.com/echen102/COVID-19-TweetIDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#access the data_samples folder to get the json tweet data for the 21:00:00 hour on January 31st, 2020\n",
    "#save the json file as a data frame\n",
    "data_dir = Path('../..') / 'data_samples/json_files/may_sample'\n",
    "json_file = str(data_dir) + '/SAMPLE-coronavirus-tweet-id-2020-05-01-00.json'\n",
    "df = pd.read_json(json_file, lines=True)\n",
    "#filter the rows to be only tweets that are in English\n",
    "en_df = df[df['lang'] == 'en']\n",
    "en_df = en_df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find how many times a link was tweeted\n",
    "This can be done for either the display_url or expanded_url. You will recieve different results depending on which URL you use. We focused on the expanded_url to narrow down the exact article and claim being tweeted. This prototype works better with a larger dataset - this prototype uses a small sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting any url links from all tweets in the dataframe\n",
    "tweet_ext_URLs = {}\n",
    "\n",
    "for i in range(len(en_df)):\n",
    "    #Filter out tweets that don't have a URL\n",
    "    if len(en_df.loc[i]['entities']['urls']) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        #Get the extended url\n",
    "        expURL = en_df.loc[i]['entities']['urls'][0]['expanded_url']\n",
    "\n",
    "        #If a URL starts with 'https://twitter.com/' it is identifying a retweet. For this prototype,\n",
    "        #we did not look at retweets.\n",
    "        if expURL.startswith('https://twitter.com/'):\n",
    "            continue\n",
    "        else: \n",
    "            #Check if the dictionary already contains that links - if it does increase its counter\n",
    "            if expURL in tweet_ext_URLs:\n",
    "                tweet_ext_URLs[expURL] += 1\n",
    "            else:\n",
    "                tweet_ext_URLs[expURL] = 1\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urlext</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://apnews.com/490aee062b36ab64c76c624f967...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://bit.ly/3bTINlI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://bit.ly/3d0UMxR</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.zerohedge.com/geopolitical/trump-w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://paper.li/e-1497917245?edition_id=5b66e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://techcrunch.com/2020/04/20/can-employer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>http://www.borderlandbeat.com/2020/04/wuhan-wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>http://dlvr.it/RVnCp0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://thehardtimes.net/culture/sesame-street...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://inspirationbylorettaexclusive.com/prod...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              urlext  count\n",
       "0  https://apnews.com/490aee062b36ab64c76c624f967...      1\n",
       "1                             https://bit.ly/3bTINlI      1\n",
       "2                             https://bit.ly/3d0UMxR      1\n",
       "3  https://www.zerohedge.com/geopolitical/trump-w...      1\n",
       "4  https://paper.li/e-1497917245?edition_id=5b66e...      1\n",
       "5  https://techcrunch.com/2020/04/20/can-employer...      1\n",
       "6  http://www.borderlandbeat.com/2020/04/wuhan-wa...      1\n",
       "7                              http://dlvr.it/RVnCp0      1\n",
       "8  https://thehardtimes.net/culture/sesame-street...      1\n",
       "9  https://inspirationbylorettaexclusive.com/prod...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Turn tweet_ext_urls into dataframes then sort by counts and view the top 10 links.\n",
    "columns = ['urlext', 'count']\n",
    "tweet_ext_df = pd.DataFrame(tweet_ext_URLs.items(), columns=columns)\n",
    "tweet_ext_df = tweet_ext_df.sort_values('count', ascending = False)\n",
    "filtered_df = tweet_ext_df.head(10)\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://apnews.com/490aee062b36ab64c76c624f9674a89c\n",
      "https://bit.ly/3bTINlI\n",
      "https://bit.ly/3d0UMxR\n",
      "https://www.zerohedge.com/geopolitical/trump-wants-us-troops-immediately-out-afghanistan-due-coronavirus\n",
      "https://paper.li/e-1497917245?edition_id=5b66e820-8b40-11ea-8c96-0cc47a0d1605\n",
      "https://techcrunch.com/2020/04/20/can-employers-mandate-covid-19-testing/\n",
      "http://www.borderlandbeat.com/2020/04/wuhan-was-fentanyl-capital-then.html\n",
      "http://dlvr.it/RVnCp0\n",
      "https://thehardtimes.net/culture/sesame-street-airs-special-episode-to-explain-coronavirus-to-the-president/\n",
      "https://inspirationbylorettaexclusive.com/products/womens-im-more-cropped-t-shirt\n"
     ]
    }
   ],
   "source": [
    "#To view the full clickable link\n",
    "for url in filtered_df['urlext']:\n",
    "    print(url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
